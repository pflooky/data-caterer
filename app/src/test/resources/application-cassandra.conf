flags {
    enableGeneratePlanAndTasks = true
    enableGeneratePlanAndTasks = ${?ENABLE_GENERATE_PLAN_AND_TASKS}
    enableCount = true
    enableCount = ${?ENABLE_COUNT}
    enableGenerateData = true
    enableGenerateData = ${?ENABLE_GENERATE_DATA}
    enableRecordTracking = true
    enableRecordTracking = ${?ENABLE_RECORD_TRACKING}
    enableDeleteGeneratedRecords = false
    enableDeleteGeneratedRecords = ${?ENABLE_DELETE_GENERATED_RECORDS}
}

folders {
    generatedPlanAndTaskFolderPath = "/tmp"
    generatedPlanAndTaskFolderPath = ${?GENERATED_PLAN_AND_TASK_FOLDER_PATH}
    planFilePath = "/plan/customer-create-plan.yaml"
    planFilePath = ${?PLAN_FILE_PATH}
    taskFolderPath = "/task"
    taskFolderPath = ${?TASK_FOLDER_PATH}
    recordTrackingFolderPath = "/tmp/data/generated/recordTracking"
    recordTrackingFolderPath = ${?RECORD_TRACKING_FOLDER_PATH}
}

metadata {
    numRecordsFromDataSource = 10000
    numRecordsFromDataSource = ${?METADATA_NUM_RECORDS_FROM_DATA_SOURCE}
    numRecordsForAnalysis = 10000
    numRecordsForAnalysis = ${?METADATA_NUM_RECORDS_FOR_ANALYSIS}
    oneOfDistinctCountVsCountThreshold = 0.1
    oneOfDistinctCountVsCountThreshold = ${?METADATA_ONE_OF_DISTINCT_COUNT_VS_COUNT_THRESHOLD}
}

generation {}

runtime{
    master = "local[*]"
    master = ${?DATA_CATERER_MASTER}
    config {
        "spark.sql.cbo.enabled" = "true"
        "spark.sql.adaptive.enabled" = "true"
        "spark.sql.cbo.planStats.enabled" = "true"
        "spark.sql.legacy.allowUntypedScalaUDF" = "true"
        "spark.sql.statistics.histogram.enabled" = "true"
        "spark.sql.shuffle.partitions" = "10"
        "spark.sql.catalog.postgres" = ""
        "spark.sql.catalog.cassandra" = "com.datastax.spark.connector.datasource.CassandraCatalog"
        "spark.hadoop.fs.s3a.directory.marker.retention" = "keep"
        "spark.hadoop.fs.s3a.bucket.all.committer.magic.enabled" = "true"
    }
}

org.apache.spark.sql.cassandra {
    cassandra {
        spark.cassandra.connection.host = "localhost"
        spark.cassandra.connection.host = ${?CASSANDRA_HOST}
        spark.cassandra.connection.port = "9042"
        spark.cassandra.connection.port = ${?CASSANDRA_PORT}
        spark.cassandra.auth.username = "cassandra"
        spark.cassandra.auth.username = ${?CASSANDRA_USERNAME}
        spark.cassandra.auth.password = "cassandra"
        spark.cassandra.auth.password = ${?CASSANDRA_PASSWORD}
    }
}

datastax-java-driver.advanced.metadata.schema.refreshed-keyspaces = [ "/.*/" ]

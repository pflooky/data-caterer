flags {
    enableGeneratePlanAndTasks = true
    enableGeneratePlanAndTasks = ${?ENABLE_GENERATE_PLAN_AND_TASKS}
    enableCount = false
    enableCount = ${?ENABLE_COUNT}
    enableGenerateData = true
    enableGenerateData = ${?ENABLE_GENERATE_DATA}
    enableRecordTracking = true
    enableRecordTracking = ${?ENABLE_RECORD_TRACKING}
    enableDeleteGeneratedRecords = false
    enableDeleteGeneratedRecords = ${?ENABLE_DELETE_GENERATED_RECORDS}
}

folders {
    generatedPlanAndTaskFolderPath = "/tmp"
    generatedPlanAndTaskFolderPath = ${?GENERATED_PLAN_AND_TASK_FOLDER_PATH}
    planFilePath = "/plan/customer-create-plan.yaml"
    planFilePath = ${?PLAN_FILE_PATH}
    taskFolderPath = "/task"
    taskFolderPath = ${?TASK_FOLDER_PATH}
    recordTrackingFolderPath = "/tmp/data/generated/recordTracking"
    recordTrackingFolderPath = ${?RECORD_TRACKING_FOLDER_PATH}
}

metadata {
    numRecordsFromDataSource = 10000
    numRecordsFromDataSource = ${?METADATA_NUM_RECORDS_FROM_DATA_SOURCE}
    numRecordsForAnalysis = 10000
    numRecordsForAnalysis = ${?METADATA_NUM_RECORDS_FOR_ANALYSIS}
    oneOfDistinctCountVsCountThreshold = 0.1
    oneOfDistinctCountVsCountThreshold = ${?METADATA_ONE_OF_DISTINCT_COUNT_VS_COUNT_THRESHOLD}
}

spark {
    master = "local[*]"
    master = ${?SPARK_MASTER}
}

# connection type
jdbc {
#   connection name
    postgres {
#       connection details
        url = "jdbc:postgresql://localhost:5432/customer"
        url = ${?POSTGRES_URL}
        user = "postgres"
        user = ${?POSTGRES_USERNAME}
        password = "postgres"
        password = ${?POSTGRES_PASSWORD}
        driver = "org.postgresql.Driver"
    }
    postgresDvd {
        url = "jdbc:postgresql://localhost:5432/dvdrental"
        url = ${?POSTGRES_URL}
        user = "postgres"
        user = ${?POSTGRES_USERNAME}
        password = "postgres"
        password = ${?POSTGRES_PASSWORD}
        driver = "org.postgresql.Driver"
    }
    mysql {
        url = "jdbc:mysql://localhost:3306/customer"
        url = ${?MYSQL_URL}
        user = "root"
        user = ${?MYSQL_USERNAME}
        password = "root"
        password = ${?MYSQL_PASSWORD}
        driver = "com.mysql.cj.jdbc.Driver"
    }
}

org.apache.spark.sql.cassandra {
    cassandra {
        spark.cassandra.connection.host = "localhost"
        spark.cassandra.connection.host = ${?CASSANDRA_HOST}
        spark.cassandra.connection.port = "9042"
        spark.cassandra.connection.port = ${?CASSANDRA_PORT}
        spark.cassandra.auth.username = "cassandra"
        spark.cassandra.auth.username = ${?CASSANDRA_USERNAME}
        spark.cassandra.auth.password = "cassandra"
        spark.cassandra.auth.password = ${?CASSANDRA_PASSWORD}
    }
}

http {
    httpbin {
        url = "http://localhost:80/put"
        url = ${?HTTP_URL}
    }
}

jms {
    solace {
        initialContextFactory = "com.solacesystems.jndi.SolJNDIInitialContextFactory"
        initialContextFactory = ${?SOLACE_INITIAL_CONTEXT_FACTORY}
        connectionFactory = "/jms/cf/default"
        connectionFactory = ${?SOLACE_CONNECTION_FACTORY}
        url = "smf://localhost:55554"
        url = ${?SOLACE_URL}
        user = "admin"
        user = ${?SOLACE_USER}
        password = "admin"
        password = ${?SOLACE_PASSWORD}
        vpnName = "default"
        vpnName = ${?SOLACE_VPN}
    }
}

kafka {
    kafka {
        kafka.bootstrap.servers = "localhost:9092"
        kafka.bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
    }
}

parquet {
    parquet {
        path = "app/src/test/resources/sample"
        path = ${?PARQUET_PATH}
    }
}

json {
    json {
        path = "app/src/test/resources/sample"
        path = ${?JSON_PATH}
    }
}

csv {
    csv {
        path = "app/src/test/resources/sample"
        path = ${?CSV_PATH}
    }
}